# ğŸ“Š Stock Analytics - Há»‡ thá»‘ng phÃ¢n tÃ­ch chá»©ng khoÃ¡n

Há»‡ thá»‘ng Big Data phÃ¢n tÃ­ch dá»¯ liá»‡u chá»©ng khoÃ¡n theo thá»i gian thá»±c, bao gá»“m cÃ¡c thÃ nh pháº§n: thu tháº­p dá»¯ liá»‡u (crawling), xá»­ lÃ½ stream (Flink), batch processing (Spark), lÆ°u trá»¯ phÃ¢n tÃ¡n (HDFS), vÃ  dá»± Ä‘oÃ¡n báº±ng Machine Learning.

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
stock-analytics/
â”œâ”€â”€ api/                        # FastAPI server - API truy váº¥n dá»¯ liá»‡u
â”‚   â”œâ”€â”€ main.py                 # Entry point cá»§a API server
â”‚   â”œâ”€â”€ router/                 # CÃ¡c endpoint routes
â”‚   â”œâ”€â”€ database/               # Káº¿t ná»‘i MongoDB
â”‚   â””â”€â”€ util/                   # Utility functions
â”‚
â”œâ”€â”€ airflow/                    # Airflow standalone (development)
â”‚   â”œâ”€â”€ dags/                   # CÃ¡c DAG workflow
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ batch-layer/                # Xá»­ lÃ½ batch vá»›i HDFS + Spark + Airflow
â”‚   â”œâ”€â”€ docker-compose.yaml     # Stack: Airflow + HDFS + Spark
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ dags/               # DAG jobs (pull data, update DW, etc.)
â”‚   â”‚   â””â”€â”€ spark-jobs/         # PySpark jobs
â”‚   â””â”€â”€ hdfs-spark/
â”‚       â””â”€â”€ config/             # Cáº¥u hÃ¬nh Hadoop, Spark, Hive
â”‚
â”œâ”€â”€ config/                     # Cáº¥u hÃ¬nh chung cho toÃ n há»‡ thá»‘ng
â”‚   â”œâ”€â”€ kafka_config.py         # Kafka configuration
â”‚   â””â”€â”€ settings.py             # Global settings
â”‚
â”œâ”€â”€ data-warehouse/             # Data Warehouse schema
â”‚   â””â”€â”€ script/
â”‚       â””â”€â”€ init.sql            # DDL cho dim tables & fact tables
â”‚
â”œâ”€â”€ deployment/                 # Deployment vá»›i Docker & K8s
â”‚   â”œâ”€â”€ docker-compose.yml      # Stack: Kafka, Flink, Redis, TimescaleDB
â”‚   â””â”€â”€ k8s/                    # Kubernetes manifests
â”‚
â”œâ”€â”€ dummy-data-source/          # API giáº£ láº­p nguá»“n dá»¯ liá»‡u
â”‚   â”œâ”€â”€ main.py                 # FastAPI mock server
â”‚   â””â”€â”€ router/
â”‚
â”œâ”€â”€ flink-jobs/                 # Apache Flink streaming jobs
â”‚   â”œâ”€â”€ news_processing_job.py  # Xá»­ lÃ½ sentiment tá»« news
â”‚   â””â”€â”€ sinks/
â”‚       â””â”€â”€ mongodb_sink.py     # Sink dá»¯ liá»‡u vÃ o MongoDB
â”‚
â”œâ”€â”€ hdfs/                       # HDFS standalone (development)
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ data/                   # Persistent data (namenode, datanode)
â”‚
â”œâ”€â”€ internal-database/          # Khá»Ÿi táº¡o dá»¯ liá»‡u ban Ä‘áº§u
â”‚   â”œâ”€â”€ data/                   # CSV/JSON source data
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ init.sql            # SQL init script
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ init_data.py        # Import dá»¯ liá»‡u ban Ä‘áº§u
â”‚       â””â”€â”€ main.py             # Pull company info tá»« API
â”‚
â”œâ”€â”€ machine-learning/           # ML models dá»± Ä‘oÃ¡n giÃ¡ cá»• phiáº¿u
â”‚   â”œâ”€â”€ train_model.py          # Train PyTorch neural network
â”‚   â”œâ”€â”€ inference.py            # Inference tá»« model Ä‘Ã£ train
â”‚   â””â”€â”€ model/
â”‚       â””â”€â”€ best_pytorch_model.pth
â”‚
â”œâ”€â”€ sql/                        # SQL schema cho analytics
â”‚   â””â”€â”€ news_analytics_schema.sql
â”‚
â”œâ”€â”€ src/                        # Source code dÃ¹ng chung
â”‚   â”œâ”€â”€ core/                   # Utility functions
â”‚   â”œâ”€â”€ crawlers/               # Data crawlers
â”‚   â”œâ”€â”€ storage/                # Storage adapters
â”‚   â””â”€â”€ streaming/              # Streaming utilities
â”‚
â”œâ”€â”€ stock-crawler-main/         # Crawler thu tháº­p dá»¯ liá»‡u chá»©ng khoÃ¡n
â”‚   â”œâ”€â”€ main.py                 # Entry point crawler
â”‚   â”œâ”€â”€ run_pipeline.py         # Pipeline Kafka producer
â”‚   â”œâ”€â”€ service/                # CÃ¡c crawler services
â”‚   â”‚   â”œâ”€â”€ company_crawler.py  # ThÃ´ng tin cÃ´ng ty
â”‚   â”‚   â”œâ”€â”€ market_crawler.py   # ThÃ´ng tin thá»‹ trÆ°á»ng
â”‚   â”‚   â”œâ”€â”€ news_crawler.py     # Tin tá»©c & sentiment
â”‚   â”‚   â””â”€â”€ ohlc_crawler.py     # Dá»¯ liá»‡u OHLC
â”‚   â””â”€â”€ utils/                  # Kafka producer, utilities
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ run_stream_jobs.py          # Entry point cho stream jobs
```

---

## ğŸš€ HÆ°á»›ng dáº«n cháº¡y há»‡ thá»‘ng

### YÃªu cáº§u
- Python 3.10+
- Docker & Docker Compose
- 16GB RAM khuyáº¿n nghá»‹

### 1. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

---

### 2. Khá»Ÿi Ä‘á»™ng Infrastructure (Kafka, Flink, Redis, TimescaleDB)

```bash
cd deployment
docker-compose up -d
```

**CÃ¡c cá»•ng Ä‘Æ°á»£c má»Ÿ:**
| Service       | Port  | URL                        | MÃ´ táº£                     |
|---------------|-------|----------------------------|---------------------------|
| Kafka         | 9092  | -                          | Message broker            |
| Kafka UI      | 8080  | http://localhost:8080      | Quáº£n lÃ½ Kafka topics      |
| Flink Web UI  | 8081  | http://localhost:8081      | Flink dashboard           |
| Redis         | 6379  | -                          | Caching                   |
| TimescaleDB   | 5432  | -                          | Time-series database      |

---

### 3. Khá»Ÿi Ä‘á»™ng Batch Layer (HDFS + Spark + Airflow)

```bash
cd batch-layer
docker-compose up -d
```

**CÃ¡c cá»•ng Ä‘Æ°á»£c má»Ÿ:**
| Service              | Port  | URL                        | MÃ´ táº£                          |
|----------------------|-------|----------------------------|--------------------------------|
| Airflow Web UI       | 8080  | http://localhost:8080      | Quáº£n lÃ½ DAGs                   |
| HDFS NameNode UI     | 9870  | http://localhost:9870      | HDFS file browser              |
| YARN ResourceManager | 8088  | http://localhost:8088      | YARN cluster status            |
| Spark History Server | 18080 | http://localhost:18080     | Spark job history              |
| Jupyter Lab          | 8888  | http://localhost:8888      | Notebook development           |
| MapReduce History    | 19888 | http://localhost:19888     | MapReduce job history          |

---

### 4. Cháº¡y API Server

```bash
# Cáº¥u hÃ¬nh environment
cd api
cp .env.example .env
# Chá»‰nh sá»­a .env vá»›i thÃ´ng tin MongoDB, etc.

# Cháº¡y server
fastapi run main.py
```

- API docs: http://localhost:8000/docs

---

### 5. Cháº¡y Data Source (Mock API)

```bash
cd dummy-data-source
cp .env.example .env
fastapi run main.py
```

---

### 6. Khá»Ÿi táº¡o dá»¯ liá»‡u ban Ä‘áº§u

```bash
cd internal-database/src

# Khá»Ÿi táº¡o database schema
python init_data.py

# Pull dá»¯ liá»‡u cÃ´ng ty (chá»‰nh year/month trong main.py)
python main.py
```

---

### 7. Cháº¡y Crawler thu tháº­p dá»¯ liá»‡u

```bash
cd stock-crawler-main

# Crawl thÃ´ng tin cÃ´ng ty theo nÄƒm/thÃ¡ng
python main.py

# Hoáº·c cháº¡y pipeline vá»›i Kafka
python run_pipeline.py
```

---

### 8. Machine Learning - Train Model

```bash
cd machine-learning

# Train model PyTorch
python train_model.py

# Inference
python inference.py
```

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stock APIs     â”‚      â”‚  News APIs      â”‚
â”‚  (Alpha Vantage)â”‚      â”‚  (Sentiment)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
         â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Stock Crawler                 â”‚
â”‚  (company, market, ohlc, news crawler)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     Kafka     â”‚
         â”‚  (Message Q)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flink Jobs   â”‚  â”‚   Batch Layer    â”‚
â”‚  (Streaming)  â”‚  â”‚ (Airflow+Spark)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚
        â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MongoDB     â”‚  â”‚      HDFS        â”‚
â”‚ (Real-time)   â”‚  â”‚  (Data Lake)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Data Warehouse  â”‚
                   â”‚  (SQL Server)    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â–¼                         â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  FastAPI Server â”‚      â”‚  ML Models      â”‚
      â”‚  (REST API)     â”‚      â”‚  (PyTorch)      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Data Warehouse Schema

### Dimension Tables
- `dim_companies` - ThÃ´ng tin cÃ´ng ty (ticker, industry, CIK, etc.)
- `dim_time` - Dimension thá»i gian
- `dim_topics` - Chá»§ Ä‘á» tin tá»©c
- `dim_news` - ThÃ´ng tin tin tá»©c

### Fact Tables
- `fact_candles` - Dá»¯ liá»‡u OHLCV (Open, High, Low, Close, Volume)
- `news_sentiment_processed` - Sentiment Ä‘Ã£ xá»­ lÃ½
- `ticker_sentiment_daily` - Sentiment tá»•ng há»£p theo ngÃ y

---

## ğŸ”§ Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

### Kafka Config (`config/kafka_config.py`)
```python
KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"
KAFKA_TOPICS = {
    "news": "stock-news",
    "ohlc": "stock-ohlc",
    "company": "stock-company"
}
```

### API Config (`api/.env`)
```env
MONGODB_URI=mongodb://localhost:27017
DATABASE_NAME=stock_analytics
```

---

## ğŸ“ Ghi chÃº

- **LÆ°u Ã½ port conflict**: Batch layer vÃ  Deployment Ä‘á»u dÃ¹ng port 8080 cho Airflow/Kafka UI. Chá»‰ cháº¡y má»™t trong hai cÃ¹ng lÃºc hoáº·c Ä‘á»•i port.
- **HDFS**: Cáº§n Ä‘á»£i HDFS khá»Ÿi Ä‘á»™ng hoÃ n táº¥t (check qua UI port 9870) trÆ°á»›c khi cháº¡y Spark jobs.
- **Airflow DAGs**: CÃ¡c DAG tá»± Ä‘á»™ng Ä‘Æ°á»£c load tá»« `batch-layer/airflow/dags/`.

---

## ğŸ‘¥ Group 7

Dá»± Ã¡n mÃ´n há»c Big Data - PhÃ¢n tÃ­ch chá»©ng khoÃ¡n thá»i gian thá»±c.
