{"timestamp":"2025-12-09T02:28:56.476216Z","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-12-09T02:28:56.477940Z","level":"info","event":"Filling up the DagBag from /workspace/airflow/dags/submit_pyspark_job.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-12-09T02:28:56.726410Z","level":"info","event":"Spark-Submit cmd: spark-submit --master yarn --num-executors 2 --total-executor-cores 2 --executor-cores 1 --executor-memory 2g --driver-memory 1g --name arrow-spark --verbose --deploy-mode client /workspace/airflow/spark-jobs/sample.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":474}
{"timestamp":"2025-12-09T02:29:03.855947Z","level":"info","event":"Using properties file: null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116310Z","level":"info","event":"Parsed arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116549Z","level":"info","event":"master                  yarn","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116647Z","level":"info","event":"remote                  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116698Z","level":"info","event":"deployMode              client","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116740Z","level":"info","event":"executorMemory          2g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116778Z","level":"info","event":"executorCores           1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116815Z","level":"info","event":"totalExecutorCores      2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116856Z","level":"info","event":"propertiesFile          null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116896Z","level":"info","event":"driverMemory            1g","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116941Z","level":"info","event":"driverCores             null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.116986Z","level":"info","event":"driverExtraClassPath    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117043Z","level":"info","event":"driverExtraLibraryPath  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117083Z","level":"info","event":"driverExtraJavaOptions  null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117121Z","level":"info","event":"supervise               false","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117250Z","level":"info","event":"queue                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117298Z","level":"info","event":"numExecutors            2","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117339Z","level":"info","event":"files                   null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117388Z","level":"info","event":"pyFiles                 null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117446Z","level":"info","event":"archives                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117580Z","level":"info","event":"mainClass               null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.117877Z","level":"info","event":"primaryResource         file:/workspace/airflow/spark-jobs/sample.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118024Z","level":"info","event":"name                    arrow-spark","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118080Z","level":"info","event":"childArgs               []","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118162Z","level":"info","event":"jars                    null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118215Z","level":"info","event":"packages                null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118256Z","level":"info","event":"packagesExclusions      null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118292Z","level":"info","event":"repositories            null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118328Z","level":"info","event":"verbose                 true","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118365Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118406Z","level":"info","event":"Spark properties used, including those specified through","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118462Z","level":"info","event":"--conf and those from the properties file null:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118513Z","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118555Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.118627Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.777952Z","level":"info","event":"Main class:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.778215Z","level":"info","event":"org.apache.spark.deploy.PythonRunner","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.778428Z","level":"info","event":"Arguments:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.778519Z","level":"info","event":"file:/workspace/airflow/spark-jobs/sample.py","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.778590Z","level":"info","event":"null","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788204Z","level":"info","event":"Spark config:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788425Z","level":"info","event":"(spark.app.name,arrow-spark)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788494Z","level":"info","event":"(spark.app.submitTime,1765247344749)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788539Z","level":"info","event":"(spark.driver.memory,1g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788583Z","level":"info","event":"(spark.executor.cores,1)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788621Z","level":"info","event":"(spark.executor.instances,2)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788660Z","level":"info","event":"(spark.executor.memory,2g)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788699Z","level":"info","event":"(spark.master,yarn)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788744Z","level":"info","event":"(spark.submit.deployMode,client)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788785Z","level":"info","event":"(spark.submit.pyFiles,)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788888Z","level":"info","event":"(spark.yarn.isPython,true)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788943Z","level":"info","event":"Classpath elements:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.788986Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.789034Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:04.789073Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:07.273862Z","level":"info","event":"25/12/09 02:29:07 INFO SparkContext: Running Spark version 3.5.7","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:07.288476Z","level":"info","event":"25/12/09 02:29:07 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:07.289337Z","level":"info","event":"25/12/09 02:29:07 INFO SparkContext: Java version 11.0.23","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:07.597382Z","level":"info","event":"25/12/09 02:29:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:07.898406Z","level":"info","event":"25/12/09 02:29:07 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:07.899243Z","level":"info","event":"25/12/09 02:29:07 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:07.899617Z","level":"info","event":"25/12/09 02:29:07 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:07.900448Z","level":"info","event":"25/12/09 02:29:07 INFO SparkContext: Submitted application: Spark Job","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:07.996642Z","level":"info","event":"25/12/09 02:29:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:08.021011Z","level":"info","event":"25/12/09 02:29:08 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:08.024375Z","level":"info","event":"25/12/09 02:29:08 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:08.188996Z","level":"info","event":"25/12/09 02:29:08 INFO SecurityManager: Changing view acls to: root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:08.190014Z","level":"info","event":"25/12/09 02:29:08 INFO SecurityManager: Changing modify acls to: root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:08.190970Z","level":"info","event":"25/12/09 02:29:08 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:08.191833Z","level":"info","event":"25/12/09 02:29:08 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:08.192417Z","level":"info","event":"25/12/09 02:29:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:09.053250Z","level":"info","event":"25/12/09 02:29:09 INFO Utils: Successfully started service 'sparkDriver' on port 36219.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:09.179666Z","level":"info","event":"25/12/09 02:29:09 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:09.323602Z","level":"info","event":"25/12/09 02:29:09 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:09.419511Z","level":"info","event":"25/12/09 02:29:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:09.420430Z","level":"info","event":"25/12/09 02:29:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:09.507144Z","level":"info","event":"25/12/09 02:29:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:09.629060Z","level":"info","event":"25/12/09 02:29:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50387fee-3295-4075-b8ef-f772670cf7dc","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:09.685935Z","level":"info","event":"25/12/09 02:29:09 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:09.812891Z","level":"info","event":"25/12/09 02:29:09 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:10.201127Z","level":"info","event":"25/12/09 02:29:10 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:10.405519Z","level":"info","event":"25/12/09 02:29:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:11.157986Z","level":"info","event":"25/12/09 02:29:11 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at namenode/172.18.0.6:8032","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:13.190273Z","level":"info","event":"25/12/09 02:29:13 INFO Configuration: resource-types.xml not found","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:13.190909Z","level":"info","event":"25/12/09 02:29:13 INFO ResourceUtils: Unable to find 'resource-types.xml'.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:13.228988Z","level":"info","event":"25/12/09 02:29:13 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:13.230048Z","level":"info","event":"25/12/09 02:29:13 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:13.230593Z","level":"info","event":"25/12/09 02:29:13 INFO Client: Setting up container launch context for our AM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:13.238154Z","level":"info","event":"25/12/09 02:29:13 INFO Client: Setting up the launch environment for our AM container","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:13.256867Z","level":"info","event":"25/12/09 02:29:13 INFO Client: Preparing resources for our AM container","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:13.324506Z","level":"info","event":"25/12/09 02:29:13 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:30.520826Z","level":"info","event":"25/12/09 02:29:30 INFO Client: Uploading resource file:/tmp/spark-cddb1438-2112-46c0-b2fa-d208f9ca2c7e/__spark_libs__15683606371884863802.zip -> hdfs://namenode:8020/user/root/.sparkStaging/application_1765246118968_0002/__spark_libs__15683606371884863802.zip","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:33.162965Z","level":"info","event":"25/12/09 02:29:33 INFO Client: Uploading resource file:/workspace/airflow/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip -> hdfs://namenode:8020/user/root/.sparkStaging/application_1765246118968_0002/pyspark.zip","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:33.302814Z","level":"info","event":"25/12/09 02:29:33 INFO Client: Uploading resource file:/workspace/airflow/.venv/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip -> hdfs://namenode:8020/user/root/.sparkStaging/application_1765246118968_0002/py4j-0.10.9.7-src.zip","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:33.705972Z","level":"info","event":"25/12/09 02:29:33 INFO Client: Uploading resource file:/tmp/spark-cddb1438-2112-46c0-b2fa-d208f9ca2c7e/__spark_conf__11607392419240047226.zip -> hdfs://namenode:8020/user/root/.sparkStaging/application_1765246118968_0002/__spark_conf__.zip","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:34.173279Z","level":"info","event":"25/12/09 02:29:34 INFO SecurityManager: Changing view acls to: root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:34.173446Z","level":"info","event":"25/12/09 02:29:34 INFO SecurityManager: Changing modify acls to: root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:34.173505Z","level":"info","event":"25/12/09 02:29:34 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:34.173548Z","level":"info","event":"25/12/09 02:29:34 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:34.173632Z","level":"info","event":"25/12/09 02:29:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:34.204951Z","level":"info","event":"25/12/09 02:29:34 INFO Client: Submitting application application_1765246118968_0002 to ResourceManager","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:34.281377Z","level":"info","event":"25/12/09 02:29:34 INFO YarnClientImpl: Submitted application application_1765246118968_0002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.285760Z","level":"info","event":"25/12/09 02:29:35 INFO Client: Application report for application_1765246118968_0002 (state: ACCEPTED)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.288933Z","level":"info","event":"25/12/09 02:29:35 INFO Client:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.289071Z","level":"info","event":"client token: N/A","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.289110Z","level":"info","event":"diagnostics: AM container is launched, waiting for AM container to Register with RM","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.289142Z","level":"info","event":"ApplicationMaster host: N/A","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.289165Z","level":"info","event":"ApplicationMaster RPC port: -1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.289184Z","level":"info","event":"queue: default","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.289204Z","level":"info","event":"start time: 1765247374247","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.289222Z","level":"info","event":"final status: UNDEFINED","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.289240Z","level":"info","event":"tracking URL: http://namenode:8088/proxy/application_1765246118968_0002/","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:35.289258Z","level":"info","event":"user: root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.310406Z","level":"info","event":"25/12/09 02:29:41 INFO Client: Application report for application_1765246118968_0002 (state: RUNNING)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311078Z","level":"info","event":"25/12/09 02:29:41 INFO Client:","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311234Z","level":"info","event":"client token: N/A","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311295Z","level":"info","event":"diagnostics: N/A","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311347Z","level":"info","event":"ApplicationMaster host: 172.18.0.5","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311392Z","level":"info","event":"ApplicationMaster RPC port: -1","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311431Z","level":"info","event":"queue: default","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311469Z","level":"info","event":"start time: 1765247374247","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311515Z","level":"info","event":"final status: UNDEFINED","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311554Z","level":"info","event":"tracking URL: http://namenode:8088/proxy/application_1765246118968_0002/","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.311590Z","level":"info","event":"user: root","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.313921Z","level":"info","event":"25/12/09 02:29:41 INFO YarnClientSchedulerBackend: Application application_1765246118968_0002 has started running.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.347016Z","level":"info","event":"25/12/09 02:29:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43793.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.347677Z","level":"info","event":"25/12/09 02:29:41 INFO NettyBlockTransferService: Server created on e932e0dc645a:43793","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.351616Z","level":"info","event":"25/12/09 02:29:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.389073Z","level":"info","event":"25/12/09 02:29:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, e932e0dc645a, 43793, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.399852Z","level":"info","event":"25/12/09 02:29:41 INFO BlockManagerMasterEndpoint: Registering block manager e932e0dc645a:43793 with 434.4 MiB RAM, BlockManagerId(driver, e932e0dc645a, 43793, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.408093Z","level":"info","event":"25/12/09 02:29:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, e932e0dc645a, 43793, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.410756Z","level":"info","event":"25/12/09 02:29:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, e932e0dc645a, 43793, None)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:41.638980Z","level":"info","event":"25/12/09 02:29:41 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> namenode, PROXY_URI_BASES -> http://namenode:8088/proxy/application_1765246118968_0002), /proxy/application_1765246118968_0002","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.116710Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /jobs: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.128144Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /jobs/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.131332Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /jobs/job: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.134005Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /jobs/job/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.135756Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /stages: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.138597Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /stages/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.140688Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /stages/stage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.144285Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /stages/stage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.147772Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /stages/pool: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.149859Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /stages/pool/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.152075Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /storage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.155388Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /storage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.157724Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /storage/rdd: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.160138Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /storage/rdd/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.162296Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /environment: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.164438Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /environment/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.167445Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /executors: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.170138Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /executors/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.172164Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /executors/threadDump: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.175000Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /executors/threadDump/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.177870Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /executors/heapHistogram: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.180613Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /executors/heapHistogram/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.183256Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /static: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.218231Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.221061Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /api: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.230857Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /jobs/job/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.231277Z","level":"info","event":"25/12/09 02:29:42 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.234821Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /stages/stage/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:42.246263Z","level":"info","event":"25/12/09 02:29:42 INFO ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:43.452471Z","level":"info","event":"25/12/09 02:29:43 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:45.863894Z","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:45.864328Z","level":"info","event":"File \"/workspace/airflow/spark-jobs/sample.py\", line 12, in <module>","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:45.881895Z","level":"info","event":"rdd.coalesce(1).saveAsTextFile(\"hdfs://namenode:8020/airflow/data/sample.txt\")","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:45.882614Z","level":"info","event":"File \"/workspace/airflow/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/rdd.py\", line 3425, in saveAsTextFile","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:45.909120Z","level":"info","event":"File \"/workspace/airflow/.venv/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1322, in __call__","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:45.944299Z","level":"info","event":"File \"/workspace/airflow/.venv/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py\", line 179, in deco","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:45.968898Z","level":"info","event":"File \"/workspace/airflow/.venv/lib/python3.12/site-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py\", line 326, in get_return_value","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.005372Z","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o42.saveAsTextFile.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.005660Z","level":"info","event":": org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://namenode:8020/airflow/data/sample.txt already exists","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.005743Z","level":"info","event":"at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.005796Z","level":"info","event":"at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:299)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.005846Z","level":"info","event":"at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.005894Z","level":"info","event":"at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopDataset$1(PairRDDFunctions.scala:1091)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.005944Z","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.005993Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006049Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006107Z","level":"info","event":"at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006163Z","level":"info","event":"at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1089)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006211Z","level":"info","event":"at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$4(PairRDDFunctions.scala:1062)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006260Z","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006311Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006356Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006402Z","level":"info","event":"at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006447Z","level":"info","event":"at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1027)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006492Z","level":"info","event":"at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$3(PairRDDFunctions.scala:1009)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006680Z","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006869Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006917Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.006967Z","level":"info","event":"at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007014Z","level":"info","event":"at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1008)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007058Z","level":"info","event":"at org.apache.spark.rdd.PairRDDFunctions.$anonfun$saveAsHadoopFile$2(PairRDDFunctions.scala:965)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007109Z","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007159Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007205Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007254Z","level":"info","event":"at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007302Z","level":"info","event":"at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:963)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007348Z","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$2(RDD.scala:1623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007600Z","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007688Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007744Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007794Z","level":"info","event":"at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007846Z","level":"info","event":"at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1623)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.007974Z","level":"info","event":"at org.apache.spark.rdd.RDD.$anonfun$saveAsTextFile$1(RDD.scala:1609)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008032Z","level":"info","event":"at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008082Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008139Z","level":"info","event":"at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008187Z","level":"info","event":"at org.apache.spark.rdd.RDD.withScope(RDD.scala:410)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008231Z","level":"info","event":"at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1609)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008279Z","level":"info","event":"at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile(JavaRDDLike.scala:564)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008322Z","level":"info","event":"at org.apache.spark.api.java.JavaRDDLike.saveAsTextFile$(JavaRDDLike.scala:563)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008365Z","level":"info","event":"at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008410Z","level":"info","event":"at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008456Z","level":"info","event":"at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008504Z","level":"info","event":"at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008549Z","level":"info","event":"at java.base/java.lang.reflect.Method.invoke(Method.java:566)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008594Z","level":"info","event":"at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008639Z","level":"info","event":"at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008683Z","level":"info","event":"at py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008753Z","level":"info","event":"at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008801Z","level":"info","event":"at py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008846Z","level":"info","event":"at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008889Z","level":"info","event":"at py4j.ClientServerConnection.run(ClientServerConnection.java:106)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008935Z","level":"info","event":"at java.base/java.lang.Thread.run(Thread.java:829)","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.008983Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.183172Z","level":"info","event":"25/12/09 02:29:46 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.183433Z","level":"info","event":"25/12/09 02:29:46 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.230789Z","level":"info","event":"25/12/09 02:29:46 INFO SparkUI: Stopped Spark web UI at http://e932e0dc645a:4040","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.257844Z","level":"info","event":"25/12/09 02:29:46 INFO YarnClientSchedulerBackend: Interrupting monitor thread","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.333526Z","level":"info","event":"25/12/09 02:29:46 INFO YarnClientSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.349044Z","level":"info","event":"25/12/09 02:29:46 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.356920Z","level":"info","event":"25/12/09 02:29:46 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.397062Z","level":"info","event":"25/12/09 02:29:46 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.465169Z","level":"info","event":"25/12/09 02:29:46 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.465433Z","level":"info","event":"25/12/09 02:29:46 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.560780Z","level":"info","event":"25/12/09 02:29:46 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.590458Z","level":"info","event":"25/12/09 02:29:46 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.700311Z","level":"info","event":"25/12/09 02:29:46 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.701501Z","level":"info","event":"25/12/09 02:29:46 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.702797Z","level":"info","event":"25/12/09 02:29:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-56bb21be-ef9a-4561-8906-0dc5a06dd43b","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.715193Z","level":"info","event":"25/12/09 02:29:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-cddb1438-2112-46c0-b2fa-d208f9ca2c7e/pyspark-0d881d5c-49b7-44c9-9faf-2f03f2758427","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:46.727156Z","level":"info","event":"25/12/09 02:29:46 INFO ShutdownHookManager: Deleting directory /tmp/spark-cddb1438-2112-46c0-b2fa-d208f9ca2c7e","logger":"airflow.task.hooks.airflow.providers.apache.spark.hooks.spark_submit.SparkSubmitHook","filename":"spark_submit.py","lineno":644}
{"timestamp":"2025-12-09T02:29:47.356152Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":980,"error_detail":[{"exc_type":"AirflowException","exc_value":"Cannot execute: spark-submit --master yarn --num-executors 2 --total-executor-cores 2 --executor-cores 1 --executor-memory 2g --driver-memory 1g --name arrow-spark --verbose --deploy-mode client /workspace/airflow/spark-jobs/sample.py. Error code is: 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/workspace/airflow/.venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":928,"name":"run"},{"filename":"/workspace/airflow/.venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1315,"name":"_execute_task"},{"filename":"/workspace/airflow/.venv/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":416,"name":"wrapper"},{"filename":"/workspace/airflow/.venv/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py","lineno":197,"name":"execute"},{"filename":"/workspace/airflow/.venv/lib/python3.12/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py","lineno":566,"name":"submit"}],"is_group":false,"exceptions":[]}]}
