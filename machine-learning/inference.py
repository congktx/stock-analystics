# FILE: inference_pytorch.py
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import requests
import joblib
import os
from datetime import datetime, timedelta, timezone
import csv

import warnings
from sklearn.exceptions import InconsistentVersionWarning
warnings.filterwarnings("ignore", category=InconsistentVersionWarning)

# --- C·∫§U H√åNH ---
MODEL_FILE = "./model/best_pytorch_model.pth"
SCALER_FILE = "./model/scaler.pkl"
API_BASE = "http://127.0.0.1:8000"
WINDOW_SIZE = 7
FEATURES = ['o', 'h', 'l', 'c', 'v']

# =========================================================
# 1. ƒê·ªäNH NGHƒ®A KI·∫æN TR√öC MODEL
# =========================================================

class StockPredictor(nn.Module):
    def __init__(self, input_dim):
        super(StockPredictor, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )

    def forward(self, x):
        return self.net(x)


def get_historical_data(ticker, target_timestamp_ms):
    """
    L·∫•y d·ªØ li·ªáu QU√Å KH·ª® d·ª±a tr√™n page_count t·ª´ API
    """
    try:
        # 1. T√≠nh to√°n kho·∫£ng th·ªùi gian (30 ng√†y)
        ts_seconds = target_timestamp_ms / 1000
        target_dt = datetime.fromtimestamp(ts_seconds)
        start_dt = target_dt - timedelta(days=30)
        from_ts_ms = int(start_dt.timestamp() * 1000)

        url = f"{API_BASE}/stock/ohlc"

        # Tham s·ªë c∆° b·∫£n (ch∆∞a c√≥ page)
        base_params = {
            "ticker": ticker,
            "from_timestamp": from_ts_ms,
            "to_timestamp": target_timestamp_ms,
            # S·ªë l∆∞·ª£ng record m·ªói trang (t√πy ch·ªânh theo API server c·ªßa b·∫°n)
            "limit": 1000
        }

        all_docs = []

        # --- B∆Ø·ªöC 1: G·ªçi Page 1 tr∆∞·ªõc ƒë·ªÉ l·∫•y Meta Data (page_count) ---
        base_params["page"] = 1

        res = requests.get(url, params=base_params, timeout=10)
        if res.status_code != 200:
            print(f"‚ùå L·ªói API Page 1: {res.status_code}")
            return None

        data = res.json()

        # L·∫•y docs trang 1
        docs = data.get("documents", [])
        if not docs:
            return None
        all_docs.extend(docs)

        # L·∫•y t·ªïng s·ªë trang
        page_count = data.get("page_count", 1)

        # --- B∆Ø·ªöC 2: V√≤ng l·∫∑p l·∫•y c√°c trang c√≤n l·∫°i (n·∫øu c√≥) ---
        if page_count > 1:
            # D√πng Session ƒë·ªÉ t√°i s·ª≠ d·ª•ng k·∫øt n·ªëi TCP -> T·∫£i nhanh h∆°n
            with requests.Session() as session:
                for p in range(2, page_count + 1):
                    base_params["page"] = p
                    try:
                        # G·ªçi API c√°c trang ti·∫øp theo
                        r = session.get(url, params=base_params, timeout=10)

                        if r.status_code == 200:
                            page_data = r.json()
                            page_docs = page_data.get("documents", [])
                            all_docs.extend(page_docs)
                            # print(f"-> ƒê√£ t·∫£i xong page {p}/{page_count}")
                        else:
                            print(f"‚ö†Ô∏è L·ªói t·∫°i page {p}: {r.status_code}")

                    except Exception as e:
                        print(f"‚ö†Ô∏è L·ªói k·∫øt n·ªëi page {p}: {e}")
                        continue  # B·ªè qua trang l·ªói, ƒëi ti·∫øp

        if not all_docs:
            return None

        # --- B∆Ø·ªöC 3: X·ª≠ l√Ω DataFrame ---
        df = pd.DataFrame(all_docs)

        # X√≥a tr√πng l·∫∑p (ƒë·ªÅ ph√≤ng API tr·∫£ tr√πng b·∫£n ghi ·ªü ranh gi·ªõi c√°c trang)
        if 't' in df.columns:
            df = df.drop_duplicates(subset=['t'])
            df = df.sort_values(by='t')

        return df

    except Exception as e:
        print(f"‚ùå L·ªói get_historical_data: {e}")
        return None


def get_future_data(ticker, current_timestamp_ms):
    """[M·ªöI] L·∫•y d·ªØ li·ªáu T∆Ø∆†NG LAI (Ng√†y h√¥m sau) ƒë·ªÉ ki·ªÉm ch·ª©ng k·∫øt qu·∫£"""
    try:
        # L·∫•y t·ª´ th·ªùi ƒëi·ªÉm hi·ªán t·∫°i + 1 gi√¢y ƒë·∫øn 7 ng√†y sau (ƒë·ªÅ ph√≤ng cu·ªëi tu·∫ßn/l·ªÖ)
        from_ts = current_timestamp_ms + 1000
        to_ts = current_timestamp_ms + (7 * 24 * 60 * 60 * 1000)

        url = f"{API_BASE}/stock/ohlc"
        params = {
            "ticker": ticker,
            "from_timestamp": from_ts,
            "to_timestamp": to_ts,
            "limit": 1,  # Ch·ªâ c·∫ßn l·∫•y c√¢y n·∫øn ƒë·∫ßu ti√™n ti·∫øp theo
            "page": 1
        }
        res = requests.get(url, params=params, timeout=5)
        if res.status_code != 200:
            return None
        docs = res.json().get("documents", [])
        if not docs:
            return None
        return docs[0]  # Tr·∫£ v·ªÅ c√¢y n·∫øn ti·∫øp theo (dict)
    except:
        return None


def prepare_input_vector(df):
    if df.empty:
        return None, None

    # 1. X·ª≠ l√Ω th·ªùi gian
    df['date'] = pd.to_datetime(df['t'], unit='ms')
    df = df.set_index('date').sort_index()
    df = df[~df.index.duplicated(keep='first')]

    # L·∫•y gi√° Close t·∫°i th·ªùi ƒëi·ªÉm d·ª± b√°o ƒë·ªÉ t√≠nh l·ª£i nhu·∫≠n th·ª±c t·∫ø sau n√†y
    current_close_price = df.iloc[-1]['c']

    # 2. Resample 1D & Fill
    daily_df = df.resample('1D').agg({
        'o': 'first', 'h': 'max', 'l': 'min', 'c': 'last', 'v': 'sum'
    }).ffill()

    # 3. T√≠nh Returns
    df_ret = daily_df[FEATURES].pct_change().replace(
        [np.inf, -np.inf], 0).dropna()

    if len(df_ret) < WINDOW_SIZE:
        print(f"Thi·∫øu d·ªØ li·ªáu: C·∫ßn {WINDOW_SIZE} ng√†y, c√≥ {len(df_ret)}")
        return None, None

    # 4. Flatten
    vec = df_ret.tail(WINDOW_SIZE).values.flatten().astype(np.float32)
    return vec, current_close_price

# =========================================================
# 3. H√ÄM D·ª∞ ƒêO√ÅN (INFERENCE)
# =========================================================


def predict_stock_pytorch(ticker, timestamp_ms):
    # --- Ki·ªÉm tra file ---
    if not os.path.exists(MODEL_FILE) or not os.path.exists(SCALER_FILE):
        print(f"‚ùå L·ªói: Thi·∫øu file model ho·∫∑c scaler.")
        return

    # --- 1. Load Model & Scaler ---
    scaler = joblib.load(SCALER_FILE)
    device = torch.device('cpu')
    model = StockPredictor(input_dim=35)

    try:
        model.load_state_dict(torch.load(MODEL_FILE, map_location=device))
        model.to(device)
        model.eval()
    except Exception as e:
        print(f"‚ùå L·ªói load model: {e}")
        return

    # --- 2. L·∫•y d·ªØ li·ªáu Input ---
    print(f"--- ƒêang l·∫•y d·ªØ li·ªáu {ticker} ---")
    df = get_historical_data(ticker, timestamp_ms)
    if df is None:
        return

    # prepare_input_vector tr·∫£ v·ªÅ c·∫£ vector input v√† gi√° hi·ªán t·∫°i
    raw_vec, current_price = prepare_input_vector(df)
    if raw_vec is None:
        return

    # --- 3. D·ª± b√°o (Model) ---
    pred_value = 0.0
    try:
        input_reshaped = raw_vec.reshape(1, -1)
        input_scaled = scaler.transform(input_reshaped)
        input_tensor = torch.tensor(
            input_scaled, dtype=torch.float32).to(device)

        with torch.no_grad():
            pred_tensor = model(input_tensor)
            pred_value = pred_tensor.item()
    except Exception as e:
        print(f"‚ùå L·ªói d·ª± b√°o: {e}")
        return

    # --- 4. Ki·ªÉm tra Th·ª±c t·∫ø (Actual) ---
    actual_return = None
    next_candle = get_future_data(ticker, timestamp_ms)

    if next_candle:
        next_price = next_candle['c']
        # C√¥ng th·ª©c Return: (Gi√° sau - Gi√° tr∆∞·ªõc) / Gi√° tr∆∞·ªõc
        actual_return = (next_price - current_price) / current_price

        next_date = datetime.fromtimestamp(
            next_candle['t']/1000).strftime('%Y-%m-%d')
    else:
        next_date = "N/A"

    # --- 5. Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
    date_str = datetime.fromtimestamp(
        timestamp_ms/1000).strftime('%Y-%m-%d %H:%M')

    print("\n" + "="*50)
    print(f"üìä K·∫æT QU·∫¢ D·ª∞ B√ÅO - M√É: {ticker}")
    print(f"üïí Th·ªùi gian Input: {date_str}")
    print(f"üí≤ Gi√° tham chi·∫øu : {current_price}")
    print("-" * 50)

    # In D·ª± b√°o
    print(f"ü§ñ Model D·ª± b√°o   : {pred_value:.6f} ({pred_value*100:+.2f}%)")

    # In Th·ª±c t·∫ø (N·∫øu c√≥)
    if actual_return is not None:
        print(
            f"üìà Th·ª±c t·∫ø (T+1)  : {actual_return:.6f} ({actual_return*100:+.2f}%)")
        print(f"üìÖ Ng√†y th·ª±c t·∫ø   : {next_date}")

        # ƒê√°nh gi√° sai s·ªë
        diff = abs(pred_value - actual_return)
        print(f"‚ö†Ô∏è Sai l·ªách (Abs) : {diff:.6f}")

        # Ki·ªÉm tra ƒë√∫ng chi·ªÅu xu h∆∞·ªõng?
        trend_pred = "TƒÇNG" if pred_value > 0 else "GI·∫¢M"
        trend_real = "TƒÇNG" if actual_return > 0 else "GI·∫¢M"

        if trend_pred == trend_real:
            print(f"‚úÖ B·∫Øt ƒë√∫ng xu h∆∞·ªõng: {trend_real}")
        else:
            print(
                f"‚ùå Sai xu h∆∞·ªõng (D·ª± b√°o {trend_pred} nh∆∞ng th·ª±c t·∫ø {trend_real})")
    else:
        print("‚ùì Th·ª±c t·∫ø        : Ch∆∞a c√≥ d·ªØ li·ªáu (T∆∞∆°ng lai)")

    print("="*50)


def predict_next_price(ticker, timestamp_ms):
    """
    H√†m tr·∫£ v·ªÅ GI√Å D·ª∞ KI·∫æN (Predicted Price) thay v√¨ % returns
    """
    # 1. Ki·ªÉm tra file
    if not os.path.exists(MODEL_FILE) or not os.path.exists(SCALER_FILE):
        print("‚ùå Thi·∫øu model ho·∫∑c scaler")
        return None

    # 2. Load Model & Scaler
    try:
        scaler = joblib.load(SCALER_FILE)
        device = torch.device('cpu')
        model = StockPredictor(input_dim=35)
        model.load_state_dict(torch.load(MODEL_FILE, map_location=device))
        model.to(device)
        model.eval()
    except Exception as e:
        print(f"‚ùå L·ªói load model: {e}")
        return None

    # 3. L·∫•y d·ªØ li·ªáu
    df = get_historical_data(ticker, timestamp_ms)
    if df is None:
        # print(f"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu cho {ticker}")
        return None

    # 4. Chu·∫©n b·ªã vector & L·∫•y gi√° hi·ªán t·∫°i
    raw_vec, current_price = prepare_input_vector(df)
    if raw_vec is None:
        # print(f"‚ö†Ô∏è Kh√¥ng ƒë·ªß d·ªØ li·ªáu 7 ng√†y cho {ticker}")
        return None

    # 5. D·ª± b√°o % bi·∫øn ƒë·ªông
    try:
        input_reshaped = raw_vec.reshape(1, -1)
        input_scaled = scaler.transform(input_reshaped)
        input_tensor = torch.tensor(
            input_scaled, dtype=torch.float32).to(device)

        with torch.no_grad():
            # K·∫øt qu·∫£ d·∫°ng % (VD: 0.02)
            pred_return = model(input_tensor).item()

        # 6. T√çNH GI√Å D·ª∞ KI·∫æN
        # C√¥ng th·ª©c: Gi√° d·ª± b√°o = Gi√° hi·ªán t·∫°i * (1 + %Bi·∫øn ƒë·ªông)
        predicted_price = current_price * (1 + pred_return)

        return predicted_price

    except Exception as e:
        print(f"‚ùå L·ªói t√≠nh to√°n: {e}")
        return None


# =========================================================
# 4. MAIN - CH·∫†Y TH·ª¨ NGHI·ªÜM
# =========================================================
if __name__ == "__main__":
    ticker = "NVDA"  
    print(f"--- D·ª∞ B√ÅO GI√Å CHO {ticker} (TH√ÅNG 10/2025) ---\n")
    print(f"{'Ng√†y':<15} | {'Gi√° d·ª± b√°o':<15}")
    print("-" * 35)
    list_ohlcvp = []
    list_ohlcvp.append(['timestamp', 'o', 'h', 'l', 'c', 'v', 'pred_price'])
    for day in range(1, 31):
        date_str = f"2025-09-{day:02d}"

        dt_obj = datetime.strptime(date_str, "%Y-%m-%d")
        dt_utc = dt_obj.replace(tzinfo=timezone.utc)
        timestamp_s = dt_utc.timestamp()
        timestamp_ms = int(timestamp_s * 1000) - 1
        
        price = predict_next_price(ticker, timestamp_ms)
        ohlcv = get_future_data(ticker, timestamp_ms)
        list_ohlcvp.append([ohlcv.get('t'), ohlcv.get('o'), ohlcv.get('h'), ohlcv.get('l'), ohlcv.get('c'), ohlcv.get('v'), price])

        if price is not None:
            print(f"{date_str:<15} | {price:.2f}")
        else:
            print(f"{date_str:<15} | {'---':<15} (Thi·∫øu Data/L·ªói)")

    with open('./data/output_lists.csv', mode='w', newline='', encoding='utf-8-sig') as file:
        writer = csv.writer(file)
        writer.writerows(list_ohlcvp) # Ghi to√†n b·ªô list m·ªôt l√∫c

    print("ƒê√£ xu·∫•t file output_lists.csv th√†nh c√¥ng!")